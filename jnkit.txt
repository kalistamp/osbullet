#!/usr/bin/env python3

import requests
from bs4 import BeautifulSoup
import time

def scrape_all_text():
    url = "https://www.wantstobehired.com/"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    # Open file to write results
    with open('all_page_text.txt', 'w', encoding='utf-8') as f:
        # Loop through all pages
        for page in range(1, 95):  # 94 pages total
            try:
                print(f"Scraping page {page}")
                
                # Get the page content
                if page == 1:
                    current_url = url
                else:
                    current_url = f"{url}?page={page}"
                
                response = requests.get(current_url, headers=headers)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Write page number as separator
                f.write(f"\n\n=== PAGE {page} ===\n\n")
                
                # Get all text from the page
                text = soup.get_text(separator='\n', strip=True)
                f.write(text)
                
                # Sleep to be nice to the server
                time.sleep(1)
                
            except Exception as e:
                print(f"Error on page {page}: {e}")
                continue

if __name__ == "__main__":
    print("Starting text scraping...")
    scrape_all_text()
    print("Done! Check all_page_text.txt for results")
